{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, test_size):\n",
    "    if isinstance(test_size, float):\n",
    "        test_size = int(test_size * len(df))\n",
    "\n",
    "    indices = df.index.tolist()\n",
    "    test_indices = random.sample(population=indices, k=test_size)\n",
    "\n",
    "    test_df = df.loc[test_indices]\n",
    "    train_df = df.drop(test_indices)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_purity(data):\n",
    "    label_column = data[:, -1]\n",
    "    unique_classes = np.unique(label_column)\n",
    "\n",
    "    if len(unique_classes) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_type_of_feature(df):\n",
    "    feature_types = []\n",
    "    n_unique_values_threshold = 1\n",
    "\n",
    "    for column in df.columns:\n",
    "        unique_values = df[column].unique()\n",
    "        example_value = unique_values[0]\n",
    "\n",
    "        if (isinstance(example_value, str)) or (len(unique_values) <= n_unique_values_threshold):\n",
    "            feature_types.append(False)\n",
    "        else:\n",
    "            feature_types.append(True)\n",
    "\n",
    "    return feature_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_counts(data):\n",
    "    labels = data[:, -1]\n",
    "    counts = {}  # a dictionary of label -> count.\n",
    "    for label in labels:\n",
    "        if label not in counts:\n",
    "            counts[label] = 0\n",
    "        counts[label] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potential_splits(data, continuous):\n",
    "    potential_splits = {}\n",
    "    _, n_columns = data.shape\n",
    "    for column_index in range(n_columns - 1):\n",
    "\n",
    "        values = data[:, column_index]\n",
    "        unique_values = np.unique(values)\n",
    "\n",
    "        continu = continuous[column_index]\n",
    "        if continu:\n",
    "            potential_splits[column_index] = []\n",
    "            for index in range(1, len(unique_values)):\n",
    "                current_value = unique_values[index]\n",
    "                previous_value = unique_values[index - 1]\n",
    "\n",
    "                potential_split = (current_value + previous_value) / 2\n",
    "\n",
    "                potential_splits[column_index].append(potential_split)\n",
    "        else:\n",
    "            potential_splits[column_index] = unique_values\n",
    "    return potential_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, split_column, split_value, continuous):\n",
    "    split_column_values = data[:, split_column]\n",
    "\n",
    "    conti = continuous[split_column]\n",
    "    if conti:\n",
    "        data_below = data[split_column_values <= split_value]\n",
    "        #     data_above = data[~(split_column_values <= split_value)]\n",
    "        data_above = data[split_column_values > split_value]\n",
    "    else:\n",
    "        data_below = data[split_column_values == split_value]\n",
    "        data_above = data[split_column_values != split_value]\n",
    "\n",
    "    return data_below, data_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(data):\n",
    "    label_column = data[:, -1]\n",
    "    _, counts = np.unique(label_column, return_counts=True)\n",
    "\n",
    "    probabilitis = counts / counts.sum()\n",
    "    entropy = np.sum(probabilitis * -np.log2(probabilitis))\n",
    "    return entropy\n",
    "\n",
    "def calculate_overall_entropy(data_below, data_above):\n",
    "    n_data_points = len(data_below) + len(data_above)\n",
    "\n",
    "    p_data_below = len(data_below) / n_data_points\n",
    "    p_data_above = len(data_above) / n_data_points\n",
    "\n",
    "    overall_entropy = (p_data_below * calculate_entropy(data_below)\n",
    "                       + p_data_above * calculate_entropy(data_above))\n",
    "\n",
    "    return overall_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gini(data):\n",
    "#     label_column = data[:, -1]\n",
    "#     _, counts = np.unique(label_column, return_counts=True)\n",
    "#     impurity = 1\n",
    "#     probabilitis = counts / counts.sum()\n",
    "#     for p in probabilitis:\n",
    "#         impurity -= p ** 2\n",
    "#     return impurity\n",
    "\n",
    "# def info_gain(left, right, current_uncertainty):\n",
    "#     p = float(len(left)) / (len(left) + len(right))\n",
    "#     lef = p * gini(left)\n",
    "#     righ = p * (1 - p) * gini(right)\n",
    "\n",
    "#     return current_uncertainty - lef - righ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_best_split(data, potential_splits, continuous):\n",
    "    overall_entropy = 999\n",
    "    best_split_column, best_split_value = None, None\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            data_below, data_above = split_data(data, split_column=column_index, split_value=value,\n",
    "                                                continuous=continuous)\n",
    "            current_overall_entropy = calculate_overall_entropy(data_below, data_above)\n",
    "\n",
    "            if current_overall_entropy <= overall_entropy:\n",
    "                overall_entropy = current_overall_entropy\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "\n",
    "    return best_split_column, best_split_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Question:\n",
    "\n",
    "    def __init__(self, column, value, header=None, continuous=False):\n",
    "        self.column = column\n",
    "        self.value = value\n",
    "        self.continuous = continuous\n",
    "        self.header = header\n",
    "\n",
    "    def match(self, row):\n",
    "        val = row[self.column]\n",
    "        if self.continuous:\n",
    "            return val <= self.value\n",
    "        else:\n",
    "            return val == self.value\n",
    "\n",
    "    def __repr__(self):\n",
    "        # This is just a helper method to print\n",
    "        # the question in a readable format.\n",
    "        condition = \"==\"\n",
    "        if self.continuous:\n",
    "            condition = \"<=\"\n",
    "\n",
    "        if self.header is None:\n",
    "            header = self.column\n",
    "        else:\n",
    "            header = self.header\n",
    "        return \"Is %s %s %s?\" % (\n",
    "            header, condition, str(self.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    def __init__(self, classes):\n",
    "        maxval = 0\n",
    "        high_c = None\n",
    "        for clas in classes:\n",
    "            if classes[clas] > maxval:\n",
    "                high_c = clas\n",
    "                maxval = classes[clas]\n",
    "        self.predictions = high_c # this is compared hence makes difference in the tree.\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decision_Node:\n",
    "    def __init__(self,\n",
    "                 question,\n",
    "                 true_branch,\n",
    "                 false_branch):\n",
    "        self.question = question\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_algorithm(df, continuous=[], column_headers=None, min_samples=2, max_depth=5):\n",
    "    # data preparations\n",
    "    if column_headers is None:\n",
    "        column_headers = df.columns\n",
    "        continuous = determine_type_of_feature(df)\n",
    "        data = df.values\n",
    "    else:\n",
    "        data = df\n",
    "\n",
    "    # BASE_CASE\n",
    "\n",
    "    class_algo = class_counts\n",
    "\n",
    "    if check_purity(data) or len(data) < min_samples or max_depth == 0:\n",
    "        classification = class_algo(data)\n",
    "        return Leaf(classification)\n",
    "\n",
    "    # helper functions\n",
    "    potential_splits = get_potential_splits(data, continuous)\n",
    "    split_column, split_value = determine_best_split(data, potential_splits, continuous)\n",
    "    data_below, data_above = split_data(data, split_column, split_value, continuous)\n",
    "    if len(data_above) == 0:\n",
    "        classification = class_algo(data_below)\n",
    "        return Leaf(classification)\n",
    "    elif len(data_below) == 0:\n",
    "        classification = class_algo(data_above)\n",
    "        return Leaf(classification)\n",
    "\n",
    "\n",
    "    # RECURSIVE_PART\n",
    "    else:\n",
    "        max_depth -= 1\n",
    "\n",
    "        # instantiate sub-tree\n",
    "        feature_name = column_headers[split_column]\n",
    "        conti = continuous[split_column]\n",
    "        question = Question(split_column, split_value, feature_name, continuous=conti)\n",
    "\n",
    "        # find answers (recursion)\n",
    "        yes_answer = decision_tree_algorithm(data_below, continuous, column_headers, min_samples, max_depth)\n",
    "        no_answer = decision_tree_algorithm(data_above, continuous, column_headers, min_samples, max_depth)\n",
    "\n",
    "        if isinstance(yes_answer, Leaf) and isinstance(no_answer, Leaf):\n",
    "            if yes_answer.predictions == no_answer.predictions:\n",
    "                return yes_answer\n",
    "\n",
    "        return Decision_Node(question, yes_answer, no_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node, spacing=\"    \"):\n",
    "\n",
    "    # Base case: we've reached a leaf\n",
    "    if isinstance(node, Leaf):\n",
    "        print(spacing[:int(len(spacing) / 2)] + \"Predict =>\", node.predictions)\n",
    "        return\n",
    "\n",
    "    # Print the question at this node\n",
    "    print(spacing + str(node.question))\n",
    "\n",
    "    # Call this function recursively on the true branch\n",
    "    print(spacing + '--> True:')\n",
    "    print_tree(node.true_branch, spacing + spacing)\n",
    "\n",
    "    # Call this function recursively on the false branch\n",
    "    print(spacing + '--> False:')\n",
    "    print_tree(node.false_branch, spacing + spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_example(example, tree):\n",
    "    if isinstance(tree, Leaf):\n",
    "        return tree.predictions\n",
    "\n",
    "    if tree.question.match(example):\n",
    "        return classify_example(example, tree.true_branch)\n",
    "    else:\n",
    "        return classify_example(example, tree.false_branch)\n",
    "\n",
    "\n",
    "def calculate_accuracy(df, tree):\n",
    "    df['classification'] = df.apply(classify_example, axis=1, args=(tree,))\n",
    "    df['classification_correct'] = df.classification == df.label\n",
    "    accuracy = df.classification_correct.mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage starts from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width   label\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./iris.csv')\n",
    "\n",
    "cols = list(df.columns)\n",
    "cols[-1] = 'label'\n",
    "df.columns = cols\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = decision_tree_algorithm(train_df, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Is petal_width <= 0.8?\n",
      "    --> True:\n",
      "    Predict => setosa\n",
      "    --> False:\n",
      "        Is petal_length <= 4.85?\n",
      "        --> True:\n",
      "        Predict => versicolor\n",
      "        --> False:\n",
      "                Is petal_width <= 1.75?\n",
      "                --> True:\n",
      "                Predict => versicolor\n",
      "                --> False:\n",
      "                Predict => virginica\n"
     ]
    }
   ],
   "source": [
    "print_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "accuracy = calculate_accuracy(test_df, tree)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
